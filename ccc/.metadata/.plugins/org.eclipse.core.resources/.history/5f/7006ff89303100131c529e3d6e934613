# -*- encoding: utf-8 -*-

require 'mongo'

#= DB "character_code_crawler" のコレクション "scrape_result" にアクセスするためのクラス
#
# anemone が抽出した項目を  scrape_result で管理する．
class ScrapeResultDao
  COLLECTION_NAME = "scrape_result"
  
  # DB に接続し ，コレクション "scrape_result" オブジェクトを生成する
  def get_collection()
    connection = Mongo::Connection.new
    db = connection.db('character_code_crawler')
    coll = db.collection(COLLECTION_NAME)
  end

  # 以前に抽出結果が登録された URL なのか，新規の URL なのかによって
  # ドキュメントを挿入するか更新するかを判断する
  def insert_or_update(coll, page_info)
    if exist?(coll, page_info.url) then
      insert(coll, page_info)
    else
      update(coll, page_info)
    end
  end
    
  # コレクション内に対象の URL が存在するか
  def exist?(coll, url)
    doc = coll.find_one("url" => url)
    if doc.to_s == "" then
      return false
    end
    puts "URL[#{url}] は既に抽出結果が登録されています"
    return true
  end
  # コレクション "scrape_result"に page_info を挿入
  def insert(coll, page_info)
    puts "#{COLLECTION_NAME} に URL[#{page_info.url}] の抽出結果を挿入します．"
    doc = {'url' => page_info.url,
           'title' => page_info.title,
           'charset' => page_info.charset, 
           'body' => page_info.body,
           'create_ts' => Time.now,
           'update_ts' => Time.now}
    coll.insert(doc)
    puts "#{COLLECTION_NAME} に URL[#{page_info.url}] の抽出結果を挿入しました．"
  end
  
  #page_info の内容を更新
  def update(coll, page_info)
    puts "#{COLLECTION_NAME} の URL[#{page_info.url}] の抽出結果を更新します．"
    coll.update({"url" => page_info.url}, 
                {"$set" => {'title' => page_info.title,
                            'charset' => page_info.charset, 
                            'body' => page_info.body,
                            'update_ts' => Time.now}})
    puts "#{COLLECTION_NAME} の URL[#{page_info.url}] の抽出結果を更新しました．"
  end

end